{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf8e365-efec-4e83-b80d-742ddbaa7528",
   "metadata": {},
   "source": [
    "# Notebook 06 - Results And Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a94c2f-b2ae-438b-be65-be41d942dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Comparison – Decision Tree vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39626a83-a202-4de4-9107-360814525d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for each model (updated)\n",
    "models = ['Decision Tree', 'Random Forest']\n",
    "accuracy = [0.76, 0.82]\n",
    "recall_ad = [0.65, 0.59]\n",
    "precision_ad = [0.67, 0.86]\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar width and positions\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Create grouped bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(index, accuracy, bar_width, label='Accuracy', color='#4C72B0')\n",
    "plt.bar(index + bar_width, recall_ad, bar_width, label='Recall (AD Class)', color='#55A868')\n",
    "plt.bar(index + 2 * bar_width, precision_ad, bar_width, label='Precision (AD Class)', color='#C44E52')\n",
    "\n",
    "# Add labels and formatting\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Comparison – Decision Tree vs Random Forest')\n",
    "plt.xticks(index + bar_width, models)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save plot\n",
    "fig = plt.gcf()\n",
    "save_plot(\n",
    "    fig,\n",
    "    filename=\"model_comparison_random_forest_vs_decision_tree.png\",\n",
    "    caption=\"Bar chart comparing accuracy, recall, and precision between Decision Tree and Random Forest models.\",\n",
    "    folder_path=\"../plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33974b-de1c-40a4-916a-60dedb5b3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "We use a grouped bar chart to compare accuracy, recall, and precision between the models. This makes it easy to see trade-offs between catching more Alzheimer’s cases and avoiding false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd888e7-989c-4479-b5e2-97758671efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Importance - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d965703-9843-4753-8e21-fb67b337632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the trained model\n",
    "importances = rf_model.feature_importances_\n",
    "features = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004ca04-77c2-4050-aa24-59eb010cd474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for sorting\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7b7c4-f13d-4c2a-8426-ce0ddb4c606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color=\"#4C72B0\")\n",
    "plt.title(\"Feature Importance – Random Forest\")\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig = plt.gcf()\n",
    "save_plot(\n",
    "    fig,\n",
    "    filename=\"random_forest_feature_importance.png\",\n",
    "    caption=\"Bar chart showing the most important features used by the Random Forest model to predict Alzheimer's diagnosis.\",\n",
    "    folder_path=\"../plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03689f5-ab9d-4b22-a8f5-c3c956caac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "This plot shows which features had the greatest influence on the Random Forest model's predictions.\n",
    "\n",
    "The top features (such as MMSE, ADL, FunctionalAssessment) were the most important in classifying whether a patient was likely to have Alzheimer’s.\n",
    "\n",
    "This helps answer our second research question:  \n",
    "**Which health and lifestyle features are most predictive of an Alzheimer’s diagnosis?**\n",
    "\n",
    "It also helps build trust in the model by showing which variables matter most.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb7d36-b79f-445a-85c4-0d386c971d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Performance Comparison – Accuracy vs ROC AUC\n",
    "In this section, we compare the performance of our three supervised models:\n",
    "- **Decision Tree**\n",
    "- **Random Forest**\n",
    "- **Logistic Regression**\n",
    "\n",
    "We visualize the results using a bar chart, showing:\n",
    "- **Accuracy**: Overall percentage of correct predictions.\n",
    "- **ROC AUC** (Area Under the Curve): How well the model separates the two classes (Alzheimer's / No Alzheimer's).\n",
    "\n",
    "This helps us identify which model performs best for our prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077bb51-c828-47a9-b413-1ca480acd350",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_accuracy = 0.75\n",
    "rf_accuracy = 0.80\n",
    "log_accuracy = 0.82\n",
    "\n",
    "dt_auc = 0.84\n",
    "rf_auc = 0.91\n",
    "log_auc = 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76abe67b-c83b-4ecf-ad23-3dbca6dad4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Random Forest', 'Logistic Regression'],\n",
    "    'Accuracy': [dt_accuracy, rf_accuracy, log_accuracy],\n",
    "    'ROC AUC': [dt_auc, rf_auc, log_auc]\n",
    "})\n",
    "\n",
    "# Bar chart\n",
    "results.set_index(\"Model\")[['Accuracy', 'ROC AUC']].plot(kind='bar', figsize=(8, 6))\n",
    "plt.title(\"Model Comparison – Accuracy and ROC AUC\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92851a-a0d1-4847-a25a-46ab302cb600",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "save_plot(\n",
    "    fig,\n",
    "    filename=\"model_comparison_bar_chart.png\",\n",
    "    caption=\"Comparison of Accuracy and ROC AUC scores for Decision Tree, Random Forest, and Logistic Regression.\",\n",
    "    folder_path=\"../plots\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7802df-da74-4702-8248-16f4918e6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### What does the model comparison chart show?\n",
    "We evaluate each model using two metrics:\n",
    "- **Accuracy**: Percentage of correct predictions on the test set.\n",
    "- **ROC AUC** (Receiver Operating Characteristic – Area Under Curve): How well the model separates Alzheimer’s vs. non-Alzheimer’s cases based on predicted probability.\n",
    "\n",
    "### What we observe:\n",
    "- **Random Forest** has the highest scores for both accuracy and AUC.  \n",
    "- **Logistic Regression** performs slightly better than Decision Tree.  \n",
    "- All models achieve good AUC scores above 0.80, which means they have strong ability to distinguish between the two classes.\n",
    "\n",
    "This helps us choose the best model for prediction:  \n",
    "**Random Forest** shows the strongest and most balanced performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabe9ac-c535-4e4f-bd42-142eebdde73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Comparison – Precision, Recall, F1-Score\n",
    "\n",
    "To compare how well our models identify Alzheimer’s patients (class 1), we extract key metrics from each classification report:\n",
    "\n",
    "- **Precision** tells us how many of the predicted positives were actually correct.\n",
    "- **Recall** tells us how many of the actual positives the model was able to detect.\n",
    "- **F1-score** is the balance between precision and recall.\n",
    "\n",
    "This allows us to see **not just accuracy**, but how safely the model can help with early diagnosis in a real-world setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fb1a8-3681-4bb7-adea-c39f39134736",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Classification Reports for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede96953-e844-488b-93bf-3f720995487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "report_dt = classification_report(y_test, dt_pred, output_dict=True)\n",
    "report_rf = classification_report(y_test, rf_pred, output_dict=True)\n",
    "report_log = classification_report(y_test, y_pred, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b1c91-4aea-4f7d-a96b-c67138eec0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "We generate the classification reports for each model (Decision Tree, Random Forest, and Logistic Regression) and convert them into dictionaries so we can extract specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d71307-2dc5-407f-8270-de2cdc502897",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Comparison DataFrame for Class 1 (Alzheimer's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52124b4a-1bf1-4ac0-9bd7-7299f31cbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table for class 1\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Decision Tree\": {\n",
    "        \"Precision\": report_dt[\"1\"][\"precision\"],\n",
    "        \"Recall\": report_dt[\"1\"][\"recall\"],\n",
    "        \"F1-score\": report_dt[\"1\"][\"f1-score\"]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"Precision\": report_rf[\"1\"][\"precision\"],\n",
    "        \"Recall\": report_rf[\"1\"][\"recall\"],\n",
    "        \"F1-score\": report_rf[\"1\"][\"f1-score\"]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"Precision\": report_log[\"1\"][\"precision\"],\n",
    "        \"Recall\": report_log[\"1\"][\"recall\"],\n",
    "        \"F1-score\": report_log[\"1\"][\"f1-score\"]\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e94b8-bf63-464a-b5fe-8d10d220fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "We focus on class 1, which represents patients diagnosed with Alzheimer’s disease.\n",
    "This allows us to evaluate how good each model is at detecting the group that matters most for early intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d63abc-e39d-469d-9b25-fb63af711d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Format and Display the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6078a9be-1293-4d98-ba1f-cac5d05f1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = comparison_df.T.round(2)\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc94bb9-ea7b-4fdf-819d-b739e9576aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "We transpose the table to make it easier to read and round the scores to two decimals for a cleaner output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56760c20-f45c-4ea3-8430-5735c939f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize as Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1adcd4-1c3c-4453-935e-a27059229893",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.plot(kind=\"bar\", figsize=(8, 6))\n",
    "plt.title(\"Precision, Recall and F1-score for Alzheimer's Class (1)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9d1cc-e063-4bc2-b5e9-ee2f9aa8ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "This bar chart gives a clear comparison of model performance for detecting Alzheimer's patients.\n",
    "We compare:\n",
    "\n",
    "- Precision: How many predicted AD cases were correct\n",
    "\n",
    "- Recall: How many real AD cases were detected\n",
    "\n",
    "- F1-score: Balance between precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68d9e1-bf9d-452b-a4b5-479864267631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure\n",
    "fig = plt.gcf()\n",
    "save_plot(\n",
    "    fig,\n",
    "    filename=\"class1_comparison_bar_chart.png\",\n",
    "    caption=\"Comparison of precision, recall and F1-score for class 1 (Alzheimer's) across three models.\",\n",
    "    folder_path=\"../plots\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574762a-43b7-4884-a257-a28ec88a493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bar Chart Plot - zoomed only for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77239a72-e68b-4694-9ff9-d5be01b997a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot grouped bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "comparison_df.plot(kind=\"bar\", ylim=(0.5, 1.0), figsize=(8, 6))\n",
    "plt.title(\"Precision, Recall, and F1-score for Class 1 – Alzheimer's\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c6107-2aa7-4f09-adc5-19d9d71b05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "\n",
    "from utils.save_tools import save_plot\n",
    "\n",
    "save_plot(\n",
    "    fig,\n",
    "    filename=\"model_precision_recall_f1_bar_chart.png\",\n",
    "    caption=\"Comparison of precision, recall, and F1-score for predicting Alzheimer's (class 1) across all trained models.\",\n",
    "    folder_path=\"../plots\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be03ac-b857-4fb5-919d-77a6f7339161",
   "metadata": {},
   "outputs": [],
   "source": [
    "### What Do We See?\n",
    "The Decision Tree performs the best on all three metrics for Alzheimer’s detection.\n",
    "\n",
    "Random Forest and Logistic Regression score lower for this class, especially on recall, which means they miss more true Alzheimer’s cases.\n",
    "\n",
    "This confirms that precision and recall are essential metrics when predicting a serious diagnosis, not just accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623809c-6007-499f-8f13-43c22ed10557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a994c28-bd0e-46d4-ac1a-7b24f7bb4e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20233727-0a81-4765-aa6a-9c3c687349e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b8211-7b10-4cc5-ac87-09681a2c49a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96efa30-b40a-42e3-9011-90d042b24bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
