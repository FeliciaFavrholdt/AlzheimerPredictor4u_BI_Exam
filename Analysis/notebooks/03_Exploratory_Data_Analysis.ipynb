{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2cfc0-e7dc-427d-8ddc-ffe0ad9419cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a051f6-0690-46e1-93d1-c6d34ba8eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistics of Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c0d69-2814-418b-a2c5-e61f47d5003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c66f61-665c-4075-b0c9-57964e6f339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output\n",
    "\n",
    "We see a full summary of the numeric columns in our cleaned dataset. This includes useful values like the mean, standard deviation, minimum and maximum, and the 25th, 50th (median), and 75th percentiles for each feature.\n",
    "\n",
    "Some columns, like Gender, Smoking, and Diagnosis, only contain values between 0 and 1. That means they are binary — either yes or no. For example, the mean of Diagnosis is about 0.35, which tells us that roughly 35% of the patients are diagnosed with the condition.\n",
    "\n",
    "Other columns, like BMI, Age, and Cholesterol, have a much wider range. These are continuous features, and we will likely need to scale them before using them in a machine learning model.\n",
    "\n",
    "This output helps us understand what kind of data we are working with. It also confirms that everything looks complete and consistent, which is important before moving on to visualizations or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc4d99-2a47-46ed-ac63-5ca234261126",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplots – All Numeric Variables\n",
    "\n",
    "We first tried creating a boxplot of all numeric features in the dataset. Boxplots are useful for showing the distribution of values, including the median, quartiles, and possible outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e528367-b385-4416-b2fa-1af235a05c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of all numeric variables\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(data=df_clean.select_dtypes(include='number'), orient=\"h\")\n",
    "plt.title(\"Boxplot of All Numeric Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e51775-2c39-45f8-90c2-c0463d166fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output\n",
    "\n",
    "We see that the boxplot is difficult to interpret because some features, like PatientID, have very large values, while others are binary or have very small ranges. This large difference in scale causes most of the boxes to be compressed or almost invisible.\n",
    "\n",
    "This shows that combining all numeric features into one boxplot is not very useful when the variables have very different value ranges. The result is a plot that does not give us any clear insight.\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc2b3d-0dcb-44f8-947a-bcadd952f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplots – Selected Continuous Features\n",
    "\n",
    "To get a clearer overview, we selected only a few continuous features that are on similar scales. This makes it easier to see the spread of values, compare medians, and identify outliers.\n",
    "\n",
    "We included variables like BMI, PhysicalActivity, DietQuality, and several cholesterol-related columns. These features have measurable ranges and are good candidates for comparison. This approach gives us a much more readable and meaningful visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071e800-74a1-4a7a-ae8b-7d9d268557a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select continuous numeric columns for clearer boxplots\n",
    "columns_to_plot = [\n",
    "    \"BMI\", \"PhysicalActivity\", \"DietQuality\", \"SleepQuality\",\n",
    "    \"CholesterolTotal\", \"CholesterolLDL\", \"CholesterolHDL\", \"MMSE\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_clean[columns_to_plot], orient=\"h\")\n",
    "plt.title(\"Boxplot of Selected Continuous Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ec022-21bc-4969-b200-1c6841b8ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output\n",
    "\n",
    "We see that the boxplots now clearly show the distribution of each selected variable. We can observe the range of values, the middle 50% (the box), and any outliers outside the whiskers.\n",
    "\n",
    "For example, CholesterolLDL and MMSE show wider ranges, while features like PhysicalActivity and DietQuality have smaller, more concentrated distributions. This tells us that these variables may need different kinds of preprocessing (like scaling) before we use them in a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d1665-dd3f-489e-9c46-a21bc071c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplots – Log-Transformed Features\n",
    "\n",
    "To improve the clarity of the boxplots even more, we applied a log transformation to each feature. Log transformation helps reduce skew, especially when there are a few very large values.\n",
    "\n",
    "This technique compresses the scale of high values and stretches the scale of low values, making the distributions easier to compare side by side. We used log(1 + x) to safely handle values near zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f99c4-2cbc-4ef5-9551-8ade4e843abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transform to reduce skew before plotting\n",
    "import numpy as np\n",
    "\n",
    "df_log = df_clean[columns_to_plot].apply(lambda x: np.log1p(x))  # log(1 + x)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_log, orient=\"h\")\n",
    "plt.title(\"Boxplot of Log-Transformed Continuous Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7cf52-63e4-4380-9771-fd07bdb766a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output\n",
    "\n",
    "We see that the log-transformed boxplots are more balanced and evenly spread. The variables are easier to compare visually, and patterns in the data are more visible. For example, MMSE had a very wide spread in the original scale, but after transformation we can clearly see its shape and outliers. The same applies to Cholesterol features.\n",
    "This confirms that log transformation is a helpful tool for visualizing skewed data and preparing features for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e184b-9047-4936-9d02-6af7480adf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Histograms for Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf9c88-67f4-4657-a08a-df031a46fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram grid for feature distributions\n",
    "df_clean.hist(figsize=(16, 12), bins=20)\n",
    "plt.suptitle(\"Histogram of Features\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2552a6-9c68-4406-b83a-f1e168eea4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Detect Outliers Using IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3aeef8-b364-476f-a4b1-396d5a7d3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df, columns):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame of rows considered outliers in any specified column using IQR method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "        outlier_indices.extend(outliers)\n",
    "\n",
    "    outlier_indices = list(set(outlier_indices))\n",
    "    return df.loc[outlier_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33432b06-383b-41a1-8ad4-98cbae3d6ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### View and Count Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e601974f-159a-453e-b557-32ca1547bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers in numeric columns\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "outliers_df = detect_outliers_iqr(df_clean, numeric_cols)\n",
    "\n",
    "print(f\"Total rows with outliers: {outliers_df.shape[0]}\")\n",
    "outliers_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b4179-1458-4229-8e12-4d45f033256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660db1b1-805e-4e51-b9df-f8a761adf2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove detected outliers\n",
    "df_no_outliers = df_clean.drop(outliers_df.index)\n",
    "\n",
    "print(f\"Shape after removing outliers: {df_no_outliers.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b9c0a-c564-4ac6-9148-ff1af065cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ed259-586f-4582-ab36-e701aedf383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outlier-free data\n",
    "df_no_outliers.to_csv(\"../data/alzheimers_no_outliers.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141f0d0-2ea3-44bf-98a2-4774c021db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd7f38-c4aa-4deb-aeb8-0448dedb9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df_no_outliers.corr(numeric_only=True), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix (Outlier-Free Data)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d15a3-3be2-424e-ac6c-61ae81e0381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Pairplot for Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139dfbee-0cd5-4e65-8b95-4f724e8bc277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: select top correlated variables for pairplot\n",
    "corr_matrix = df_no_outliers.corr(numeric_only=True)\n",
    "top_corr = corr_matrix.abs().unstack().sort_values(ascending=False)\n",
    "top_pairs = top_corr[(top_corr < 1.0)].drop_duplicates().head(3)\n",
    "\n",
    "cols = list(set([i for pair in top_pairs.index for i in pair]))\n",
    "sns.pairplot(df_no_outliers[cols])\n",
    "plt.suptitle(\"Pairplot of Top Correlated Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bbfbb-7984-46fc-885b-d118d5e7d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492f1a8-c8b6-4514-b5fa-438073082fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric columns\n",
    "scaler = StandardScaler()\n",
    "df_scaled = df_no_outliers.copy()\n",
    "df_scaled[numeric_cols] = scaler.fit_transform(df_no_outliers[numeric_cols])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
