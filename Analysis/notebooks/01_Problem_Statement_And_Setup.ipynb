{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94bd51a-3cf1-47fd-ae96-47a67b4db05f",
   "metadata": {},
   "source": [
    "# Notebook 01 - Problem Statement And Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2752407-fbab-4613-88ca-ed7e0ff448a1",
   "metadata": {},
   "source": [
    "## Project Title  \n",
    "**AlzheimerPredictor4u**\n",
    "\"Early Detection of Alzheimer’s Disease Using Predictive Analytics\"\n",
    "\n",
    "## Contributors\n",
    "**Group 4, l25dat4bi1f**\n",
    "Business Intelligence 2025  \n",
    "Copenhagen Business Academy, Lyngby  \n",
    "\n",
    "### Felicia Favrholdt\n",
    "- Email: [cph-ff62@cphbusiness.dk](mailto:cph-ff62@cphbusiness.dk)  \n",
    "- GitHub: [https://github.com/FeliciaFavrholdt](https://github.com/FeliciaFavrholdt)\n",
    "\n",
    "### Fatima Majid Shamcizadh\n",
    "- Email: [cph-fs156@cphbusiness.dk](mailto:cph-fs156@cphbusiness.dk)  \n",
    "- GitHub: [https://github.com/Fati01600](https://github.com/Fati01600)\n",
    "\n",
    "## GitHub Links  \n",
    "- **Repository**: [AlzheimerPredictor4u_BI_Exam](https://github.com/FeliciaFavrholdt/AlzheimerPredictor4u_BI_Exam.git)  \n",
    "- **Streamlit Folder**: Located inside the same repository under /Streamlit_app/\n",
    "\n",
    "## Original Dataset Link \n",
    "https://www.kaggle.com/datasets/rabieelkharoua/alzheimers-disease-dataset/data\n",
    "\n",
    "## Problem Statement  \n",
    "*How can we use Business Intelligence and AI techniques to assess the risk of Alzheimer's disease based on demographic and lifestyle factors such as age, gender, health status, and daily habits, in order to support early detection and improve preventive care strategies?”*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd6b31-a8d5-48ef-8880-6b1c91d7d42d",
   "metadata": {},
   "source": [
    "## Research Questions  \n",
    "1. Can we predict the risk of Alzheimer's disease based on demographic and lifestyle factors such as age, gender, physical activity, and diet?\n",
    "2. Which health and lifestyle features are most predictive of an Alzheimer’s diagnosis?\n",
    "3. Can we build a predictive dashboard to visualize individual risk levels and support clinical decision-making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a243dc58-9256-43b9-b0fb-3d10f5babd3b",
   "metadata": {},
   "source": [
    "## Motivation \n",
    "Our motivation is to help doctors and healthcare professionals identify people who are at high risk of developing Alzheimer’s disease before symptoms become severe. Alzheimer’s is a progressive condition that affects memory and thinking, and early detection can make a big difference in how the disease is managed. In this project, we want to explore how Business Intelligence (BI) and Artificial Intelligence (AI) can be used to analyze real patient data, including age, gender, health conditions, and lifestyle habits like diet and exercise. By finding patterns in the data, we hope to build a smart system that can support earlier diagnosis, so doctors can take action sooner and improve patient outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecba0c9-6703-4f0f-bc46-8ea9e64bcfff",
   "metadata": {},
   "source": [
    "## Project Goals\n",
    "The main goal of this project is to build a simple and practical system that can help doctors and healthcare staff assess a person’s risk of developing Alzheimer’s disease. We want to do this by using Business Intelligence (BI) and Artificial Intelligence (AI) techniques on real patient data. Our goals include:\n",
    "\n",
    "- Creating a machine learning model that can predict the likelihood of an Alzheimer’s diagnosis\n",
    "- Identifying which features—such as age, gender, health conditions, and lifestyle habits—are most strongly linked to Alzheimer’s risk\n",
    "- Designing an interactive dashboard that presents predictions and feature insights in a clear, user-friendly way for clinical use\n",
    "\n",
    "## Hypotheses\n",
    "In this project, we expect to discover the following patterns in the dataset:\n",
    "\n",
    "- H1: Patients over the age of 75 are more likely to be diagnosed with Alzheimer’s than younger individuals\n",
    "- H2: Lower MMSE (Mini-Mental State Exam) scores and higher CDR (Clinical Dementia Rating) scores are strong indicators of Alzheimer’s diagnosis\n",
    "- H3: Patients who report higher physical activity and better diet quality show lower risk levels for Alzheimer’s disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631666f-f139-43a9-a2d2-3c53d1abb157",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Project Scope and Impact\n",
    "This project looks at how we can use Business Intelligence (BI) and machine learning to help detect Alzheimer’s disease early. We use a real dataset with over 2,000 patients, including information like age, gender, health conditions, and lifestyle habits. By analyzing this data, we want to build a system that helps doctors understand who might be at risk of developing Alzheimer’s before symptoms get too serious. The goal is to support better and faster decisions in healthcare using data.\n",
    "    \n",
    "### Key Objectives\n",
    "- Use real patient data to train a model that can predict the risk of Alzheimer’s disease\n",
    "- Find out which features (like age, diet, exercise, or test scores) are most useful for making predictions\n",
    "- Clean and prepare the data using BI methods so it’s ready for analysis\n",
    "- Build an easy-to-use dashboard that shows predictions clearly for doctors and nurses\n",
    "- Keep everything well-documented in Jupyter Notebooks and share the project on GitHub\n",
    "\n",
    "## Expected Outcomes\n",
    "By the end of the project, we expect to have:\n",
    "\n",
    "- A clean and organized dataset that’s ready for analysis\n",
    "- A working machine learning model that can predict Alzheimer’s risk\n",
    "- Saved figures, charts, and trained models for future use\n",
    "- A simple web dashboard built with Streamlit to explore the results\n",
    "- Clear documentation of the problem, how we solved it, and what we learned\n",
    "- All code and results stored in a public GitHub repository\n",
    "\n",
    "## Impact and Beneficiaries\n",
    "Our project can help healthcare professionals, like doctors and nurses, spot Alzheimer’s earlier and plan better care. It saves time, improves decision-making, and helps patients get support sooner. The dashboard and predictions could be useful in hospitals, clinics, or memory care units — especially for teams working with older patients or those showing early signs of memory problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b4c3a-4fad-4d3a-819f-e7782ed43187",
   "metadata": {},
   "source": [
    "## Brief Annotation\n",
    "\n",
    "**1. Which challenge would you like to address?**  \n",
    "We want to solve the challenge of detecting Alzheimer’s disease early by analyzing patient data such as age, gender, health history, and lifestyle habits. Our goal is to use data to find patterns that show who might be at higher risk, so healthcare professionals can act sooner and provide the right care.\n",
    "    \n",
    "**2. Why is this challenge an important or interesting research goal?**  \n",
    "Alzheimer’s is a serious illness that affects memory and daily life, and it worsens over time. Early detection is key, but it’s not always easy. If we can use data to spot early warning signs, doctors can respond faster, which can help improve quality of life and slow the progression of the disease.    \n",
    "\n",
    "**3. What is the expected solution your project would provide?**  \n",
    "We plan to build a machine learning model that uses real patient data to predict a person’s risk of Alzheimer’s. The results will be shown in a simple, visual dashboard that helps doctors and nurses quickly understand the predictions and which factors matter most.\n",
    "    \n",
    "**4. What would be the positive impact of the solution, and which category of users could benefit from it?**  \n",
    "Our solution can support doctors, nurses, and caregivers by giving them better tools to detect Alzheimer’s earlier. It could be used in clinics, hospitals, or memory care units to make smarter decisions, save time, and improve care for patients who need it most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc0c55-8e4d-4696-822b-61d56c3d4416",
   "metadata": {},
   "source": [
    "## Notebooks \n",
    "The project is implemented through the 5 modular notebooks, each focused on a specific phase of the BI and AI workflow:\n",
    "\n",
    "- **01_Problem_Statement_and_Setup**\n",
    "Define the project scope, research goals, problem formulation, and setup. This includes creating the folder structure, initializing libraries, and documenting the project plan to ensure a clean and reproducible environment.\n",
    "\n",
    "- **02_Data_Loading_And_Preprocessing**\n",
    "Load the Alzheimer’s dataset, inspect for missing values, rename columns, and remove duplicates. Perform data cleaning, encode categorical variables, scale numerical values, and handle outliers. Prepare the dataset for modeling by selecting key features related to Alzheimer’s risk.\n",
    "\n",
    "- **03_Exploratory_Data_Analysis (EDA)**\n",
    "Explore the data using descriptive statistics and BI visualizations. Generate histograms, boxplots, and correlation heatmaps to understand patterns across age, gender, lifestyle habits, and diagnosis. Identify potential risk indicators.\n",
    "\n",
    "- **04_Model_Training_and_Evaluation**\n",
    "Train classification models (e.g., Logistic Regression, Decision Trees, Random Forest) to predict Alzheimer’s diagnosis risk. Evaluate model performance using accuracy, precision, recall, confusion matrices, and cross-validation.\n",
    "\n",
    "- **05_Results_and_Interpretation**\n",
    "Present the final model results and analyze which features were most important for predictions. Prepare visual outputs for the dashboard and write a summary explaining the model’s performance, strengths, and limitations in a clinical context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973c0d4-ea9b-4e69-bef6-368af195e7be",
   "metadata": {},
   "source": [
    "## Streamlit Application\n",
    "We are building a separate Streamlit web app to make our results easy to explore and understand — even for users without technical knowledge. The app will let doctors and healthcare staff interact with the predictions and visualizations in a simple and clear interface. Users will be able to upload data, view charts, and see model results that show the predicted risk of Alzheimer’s.\n",
    "\n",
    "The dashboard will include visual tools like bar charts, feature importance plots, and summary tables. These elements help users compare different patients, see which features matter most, and understand what drives the predictions. The app will be created using standard Python libraries and will be included in a separate /streamlit_app/ folder in our GitHub repository.\n",
    "\n",
    "To make the dashboard even more interactive, we will integrate a built-in chatbot using RAG (Retrieval-Augmented Generation). This chatbot will answer questions based on the project data and model results, helping users quickly understand insights and explore explanations — all in natural language. It’s designed to support doctors and nurses who need fast, clear answers without diving into the technical details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c7f74-e19e-46a0-9c47-08ed79453e4c",
   "metadata": {},
   "source": [
    "## Execution Plan: BI Sprints\n",
    "\n",
    "**Sprint 1: Problem Formulation**  \n",
    "Notebook: 01_Problem_Statement_And_Setup.ipynb\n",
    "Focus: Define the business case, problem formulation, research questions, and hypotheses. Set up the project environment, folder structure, and GitHub workflow. Document all planning steps to ensure a reproducible project foundation.\n",
    "\n",
    "**Sprint 2: Data Collection & Preprocessing**  \n",
    "Notebook: 02_Data_Loading_And_Preprocessing.ipynb \n",
    "Focus: Load the Alzheimer’s dataset, inspect and clean the data, handle missing values and outliers, and prepare it for analysis. Apply data transformation, scaling, and encoding to shape the dataset for modeling.   \n",
    "                                                                                                                                                                                                       \n",
    "**Sprint 3: Machine Learning & Evaluation**  \n",
    "Notebooks: 03_Exploratory_Data_Analysis.ipynb, 04_Model_Training_and_Evaluation.ipynb\n",
    "Focus: Use descriptive statistics and visualizations to explore key patterns and relationships in the data. Then train classification models to predict Alzheimer’s risk, evaluate them using performance metrics, and select the best model.\n",
    "\n",
    "**Sprint 4: Business Application**  \n",
    "Notebook: 05_Results_and_Interpretation.ipynb\n",
    "Streamlit App: streamlit_app/streamlit_app.py\n",
    "Focus: Build a user-friendly Streamlit dashboard that presents predictions, feature importance, and key visuals. Integrate a chatbot using RAG (Retrieval-Augmented Generation) to allow users to ask questions and receive clear, natural language answers based on the model and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175b0dd-cbec-48d0-b7e9-637fcfe1baee",
   "metadata": {},
   "source": [
    "### Team Member Engagement\n",
    "\n",
    "| Member    | Responsibility                                       | Sprint Phase                   | Deadline          |\n",
    "|-----------|------------------------------------------------------|--------------------------------|-------------------|\n",
    "| Fatima    | Problem formulation, goals, and setup                | Sprint 1: Problem Formulation  | Wednesday 4/6-25  |\n",
    "| Felicia   | Data loading, cleaning, and transformation           | Sprint 2: Data Preparation     | Sunday 8/6-25     |\n",
    "| Felicia   | Model training, tuning, and evaluation               | Sprint 3: Machine Learning     | Thursday 12/6-25  |\n",
    "| Fatima    | Dashboard development and chatbot integration        | Sprint 4: Business Application | Monday 15/6-25    |\n",
    "| Together  | Cleanup – refactoring, typos, comments etc.          | Sprint 5: Prepare Handin       | Monday 16/6-25    |\n",
    "| Together  | Final checks and delivery                            | Project Deadline               | Tuesday 17/6-25   |\n",
    "\n",
    "Both team members actively participated in reviewing, testing, and refining the work before each deliverable was uploaded to GitHub or submitted for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224bf3e7-ce21-4598-a70f-50c0aeb85015",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Project Directory Structure\n",
    "\n",
    "The project is organized in the following folder structure to support modular development, collaboration, and reproducibility:\n",
    "\n",
    "```\n",
    "/AlzheimerPredictor4u_BI_Exam/\n",
    "│\n",
    "├── data/                          # Raw and cleaned datasets (CSV files)\n",
    "│   ├── alzheimers_disease_raw_data.csv\n",
    "│   └── alzheimers_clean.csv\n",
    "│\n",
    "├── models/                        # Saved machine learning models (.pkl, .joblib)\n",
    "│\n",
    "├── plots/                         # Generated figures, histograms, and visualizations\n",
    "│\n",
    "├── reports/                       # JSON summaries for notebooks and results\n",
    "│   ├── 01_problem_statement_and_setup_summary_<timestamp>.json\n",
    "│   └── 02_data_loading_and_preprocessing_summary_<timestamp>.json\n",
    "│\n",
    "├── notebooks/                     # Jupyter notebooks for each sprint\n",
    "│   ├── 01_Problem_Statement_And_Setup.ipynb\n",
    "│   ├── 02_Data_Loading_And_Preprocessing.ipynb\n",
    "│   ├── 03_Exploratory_Data_Analysis.ipynb\n",
    "│   ├── 04_Model_Training_and_Evaluation.ipynb\n",
    "│   └── 05_Results_and_Interpretation.ipynb\n",
    "│\n",
    "├── utils/                         # Custom utility modules\n",
    "│   ├── __init__.py\n",
    "│   ├── setup_notebook.py                   # Environment setup and data inspection tools\n",
    "│   └── save_tools.py              # Plot and summary saving tools\n",
    "│\n",
    "├── Streamlit_app/                 # Streamlit web app for model deployment\n",
    "│   └── streamlit_app.py\n",
    "│\n",
    "├── requirements.txt               # Python package dependencies\n",
    "├── README.md                      # Project overview and instructions\n",
    "├── .gitignore                     # Files/folders excluded from Git\n",
    "├── BI_Exam_Questions.pdf          # Reference exam question list\n",
    "└── Exam-Project.pdf               # Official project description\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4da6d5-4af7-470d-9889-f81155dfbb69",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "This project uses a standard Python environment for data analysis, machine learning, and web-based dashboard development. To ensure consistent and reproducible results across platforms, all paths are defined as relative, and setup is automated with utility scripts.\n",
    "\n",
    "### Libraries Used\n",
    "We use widely adopted Python libraries for each major task:\n",
    "\n",
    "- **pandas** – For data manipulation and DataFrame operations\n",
    "- **numpy** – For numerical processing\n",
    "- **matplotlib** and **seaborn** – For data visualization and styling\n",
    "- **scikit-learn** – For preprocessing, model training, and evaluation\n",
    "- **joblib** – For saving and loading machine learning models\n",
    "- **streamlit** – For building the interactive dashboard application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78f49b-79d8-46c7-b4e2-e67b070a2276",
   "metadata": {},
   "source": [
    "### Development Tools\n",
    "\n",
    "- **IDE**: Visual Studio Code with Jupyter extension\n",
    "- **Environment Management**: Anaconda or pip via requirements.txt\n",
    "- **Version Control**: Git with GitHub repository integration\n",
    "- **Deployment Tools**: Jupyter Notebooks for analysis and Streamlit for delivery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2ba8e-c5cc-460f-9911-6eb731c5efb4",
   "metadata": {},
   "source": [
    "### Platform Requirements\n",
    "To run the project and notebooks successfully, ensure the following software versions are installed:\n",
    "\n",
    "- **Python** 3.9 or higher  \n",
    "- **Jupyter Notebook** (or Visual Studio Code with Jupyter extension)  \n",
    "- **Streamlit** version 1.20 or later  \n",
    "\n",
    "All notebooks are executed from within the /notebooks/ directory. Output files such as datasets, visualizations, and model summaries are saved to corresponding subdirectories located one level up for consistency across the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d0dcd-4088-4fd9-992d-5a1909ec1b7c",
   "metadata": {},
   "source": [
    "### Dependency Management\n",
    "\n",
    "To keep the project environment consistent, all dependencies are listed in a requirements.txt file located in the root directory. This file ensures that every team member or external reviewer can recreate the exact environment using one command. The file ensures that all libraries required for notebooks, machine learning, visualizations, and Streamlit apps are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6000edd-d9bb-4f89-8453-56832fe07b92",
   "metadata": {},
   "source": [
    "**How to Install**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e938e2b-fdf9-47fe-a021-45be6a5f27de",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1390303618.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[55], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install -r requirements.txt\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# bash - inside a terminal window place:\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "407d61ea-c8a4-4f38-be64-dcfc80c68b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from -r ../../requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from -r ../../requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from -r ../../requirements.txt (line 3)) (3.9.2)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.12/site-packages (from -r ../../requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from -r ../../requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: streamlit in /opt/anaconda3/lib/python3.12/site-packages (from -r ../../requirements.txt (line 6)) (1.37.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from -r ../../requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.12/site-packages (from -r ../../requirements.txt (line 8)) (5.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->-r ../../requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->-r ../../requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->-r ../../requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r ../../requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r ../../requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r ../../requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (16.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (4.13.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from streamlit->-r ../../requirements.txt (line 6)) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit->-r ../../requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit->-r ../../requirements.txt (line 6)) (4.23.0)\n",
      "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit->-r ../../requirements.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r ../../requirements.txt (line 6)) (4.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r ../../requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit->-r ../../requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit->-r ../../requirements.txt (line 6)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit->-r ../../requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit->-r ../../requirements.txt (line 6)) (2025.4.26)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit->-r ../../requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit->-r ../../requirements.txt (line 6)) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r ../../requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit->-r ../../requirements.txt (line 6)) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r ../../requirements.txt (line 6)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r ../../requirements.txt (line 6)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r ../../requirements.txt (line 6)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r ../../requirements.txt (line 6)) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r ../../requirements.txt (line 6)) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "# python - inside jupytor\n",
    "!pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d6e24b-ce67-404a-b35e-c7212c3800bc",
   "metadata": {},
   "source": [
    "## Project initialization\n",
    "\n",
    "The setup routine is handled via a helper function in utils/setup.py. This script ensures that the working environment is consistent across machines and ready for use in any notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81ad1772-e1e8-4cc6-8d20-4e6803a35e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory of utils to path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from utils.setup import init_environment\n",
    "init_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98916928-02b4-47fc-aaf5-9cdf26578c13",
   "metadata": {},
   "source": [
    "#### What init_environment() Does\n",
    "The init_environment() function performs the following:\n",
    "\n",
    "- Applies a consistent visual style using Seaborn and Matplotlib\n",
    "- Verifies that key directories exist: ../data, ../models, ../plots, ../reports\n",
    "- Ensures that all notebooks start from a clean and ready-to-use environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee9bf5-507d-4035-a5c8-e34be45a29fc",
   "metadata": {},
   "source": [
    "## Saving Project Summaries and Visual Outputs\n",
    "\n",
    "To keep track of our progress and ensure reproducibility, we use custom utility functions from the utils/save_tools.py script.\n",
    "We use save_notebook_and_summary() to generate structured JSON logs for each notebook. These summaries capture important metadata like:\n",
    "\n",
    "- Contributors involved\n",
    "- Description of the notebook’s purpose\n",
    "- Tools and libraries used\n",
    "- Notebooks and folders created\n",
    "- Milestones covered in the BI sprint plan\n",
    "\n",
    "Both functions help us maintain a well-documented and organized workflow, which is important for collaboration, exam evaluation, and public sharing via GitHub or Streamlit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12b7d813-17e4-4e86-a3a2-c8c226b72eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to: ../reports/01_problem_statement_and_setup_summary_2025-06-06_16-09-11.json\n"
     ]
    }
   ],
   "source": [
    "from utils.save_tools import save_notebook_and_summary\n",
    "\n",
    "save_notebook_and_summary(\n",
    "    notebook_name=\"01_problem_statement_and_setup\",\n",
    "    summary={\n",
    "        \"description\": \"Defined project scope, goals, research questions, folder structure, and reusable tools for saving figures and notebook summaries.\",\n",
    "        \"team_members\": [\n",
    "            \"Felicia Favrholdt\",\n",
    "            \"Fatima Majid Shamcizadh\"\n",
    "        ],\n",
    "        \"sprints_defined\": 4,\n",
    "        \"notebooks_planned\": [\n",
    "            \"01_Problem_Statement_And_Setup\",\n",
    "            \"02_Data_Loading_And_Preprocessing\",\n",
    "            \"03_Exploratory_Data_Analysis\",\n",
    "            \"04_Model_Training_and_Evaluation\",\n",
    "            \"05_Results_and_Interpretation\"\n",
    "        ],\n",
    "        \"folders_created\": [\n",
    "            \"data\", \"models\", \"plots\", \"reports\"\n",
    "        ],\n",
    "        \"tools_used\": [\n",
    "            \"Python 3.9\",\n",
    "            \"Jupyter Notebook\",\n",
    "            \"Visual Studio Code\",\n",
    "            \"GitHub\",\n",
    "            \"Streamlit\",\n",
    "            \"seaborn\",\n",
    "            \"scikit-learn\"\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7fdcb6-62c1-4426-b739-c37a5c59cf0d",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed42bbb-9487-4773-8ff3-99241f998cda",
   "metadata": {},
   "source": [
    "## How We Save Histograms, Boxplots, and Other Figures\n",
    "\n",
    "To ensure consistency, organization, and easy reuse of our visualizations, we created a custom helper function called save_plot() in utils/save_tools.py. This function automatically saves each figure (e.g., histograms, boxplots, correlation heatmaps) to the plots/ folder. It also creates a .txt file containing a human-readable caption, which we use directly in our Streamlit dashboard.\n",
    "\n",
    "This process helps us:\n",
    "- Maintain organized, timestamped visuals across notebooks and sprints\n",
    "- Easily load images and captions in Streamlit using st.image()\n",
    "- Preserve clean notebook outputs (we use plt.close() after saving)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85053f5a-1e1f-4fc6-af7c-f6810e506662",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064b7070-1059-491f-a9d9-c0d9217bbc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
